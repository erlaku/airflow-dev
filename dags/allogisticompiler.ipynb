{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pau9t5HruIvl"
      },
      "source": [
        "## Compile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "ARteWK-frRP0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "url = 'https://docs.google.com/spreadsheets/d/1a38_dvN00Ycq1gv21fqf7Q3q_5ZvxsclC3KR0yD4jJI/export?format=csv&gid='\n",
        "# df_rbb = pd.read_csv(url+'922405458')\n",
        "# # df_o2o = pd.read_csv(url+'0')\n",
        "# df_es = pd.read_csv(url+'1439568429')\n",
        "# df_ll = pd.read_csv(url+'1874858690')\n",
        "# df_ex = pd.read_csv(url+'1140683626')\n",
        "# df_mj = pd.read_csv(url+'1229483984')\n",
        "\n",
        "# df_o2o = pd.read_csv(url+'1229483984')\n",
        "\n",
        "# df_24 = pd.read_csv(url+'982555558')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "bdNcnDZq1hXI"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Erland\\AppData\\Local\\Temp\\ipykernel_1880\\1892608526.py:71: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df_24e = df_24.groupby(['id','status','type_ex']).apply(agg_func).reset_index(drop=True)\n"
          ]
        }
      ],
      "source": [
        "df_24 = pd.read_csv(url+'982555558')\n",
        "\n",
        "df_24 = df_24[~((df_24['type'].isna()) | (df_24['type'] == '#REF!'))]\n",
        "\n",
        "df_24['status'] = df_24['status'].fillna('In Progress')\n",
        "df_24['n_req'] = df_24['n_req'].fillna(1)\n",
        "df_24['type'] = df_24['type'].str.lower()\n",
        "\n",
        "df_24['rbb_schedule'] = df_24['rbb_schedule'].apply(lambda x: f\"{int(x)}\" if pd.notnull(x) else '')\n",
        "\n",
        "df_24['id'] = df_24['id'].astype('string')\n",
        "\n",
        "df_24['type_ex'] = df_24['type'].apply(lambda x: x if 'exchange' in x else '')\n",
        "\n",
        "def transform_type(value):\n",
        "    value = value.lower().replace(\" \", \"\")\n",
        "    if 'exchange' in value:\n",
        "      if 'pickup' in value:\n",
        "        return 'exchange - pickup'\n",
        "      else:\n",
        "        return 'exchange - exchange'\n",
        "    elif 'maujual' in value:\n",
        "        return 'mj'\n",
        "    else:\n",
        "        return value\n",
        "\n",
        "df_24['type'] = df_24['type'].apply(transform_type)\n",
        "\n",
        "def agg_func(group):\n",
        "    result = group.iloc[0].copy()\n",
        "    result['n_req'] = group['n_req'].count()\n",
        "    return result\n",
        "\n",
        "\n",
        "\n",
        "df_temp = df_24.groupby(['id', 'type', 'pickup0']).last().reset_index()\n",
        "df_temp['attemptCount'] = 1\n",
        "df_temp = df_temp.groupby(['id','type'])['attemptCount'].sum().reset_index()\n",
        "\n",
        "# df_24['attemptCount'] = df_24[df_24['status'] == 'Reschedule'].groupby(['id', 'pickup0'])['status'].transform('count')\n",
        "# df_24['attemptCount'] = df_24['attemptCount'].fillna(1)\n",
        "\n",
        "df_24['temp'] = df_24['id'] + df_24['type']\n",
        "df_temp['temp'] = df_temp['id'] + df_temp['type']\n",
        "\n",
        "df_temp = df_24.merge(df_temp, on='temp', how='left', suffixes=('', '_temp'))\n",
        "df_24['attemptCount'] = df_temp['attemptCount'].fillna(1)\n",
        "df_24.drop(columns='temp', inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "df_temp = df_24[~df_24['pickup0'].isna()].groupby('id')['pickup0'].min().reset_index()\n",
        "df_temp = df_24.merge(df_temp, on='id', how='left', suffixes=('', '_temp'))\n",
        "\n",
        "df_24['pickup0'] = df_temp['pickup0_temp']\n",
        "\n",
        "df_24 = df_24[~((df_24['status'] == 'Reschedule') & df_24['id'].isin(df_24[df_24['status'] != 'Reschedule']['id']))]\n",
        "\n",
        "\n",
        "# -------------------------------------------- logistic change -> success --------------------------------------------\n",
        "\n",
        "r_list = df_24[df_24['status'].isin(['Reschedule', 'In Progress'])]['rbb_schedule'].dropna().unique().tolist()\n",
        "s_list = df_24[df_24['status'].str.lower() == 'success']['rbb_schedule'].dropna().unique().tolist()\n",
        "\n",
        "common_list = list(set(r_list).intersection(s_list))\n",
        "\n",
        "df_24 = df_24[~(df_24['rbb_schedule'].isin(common_list) & (df_24['status'].str.lower() != 'success'))]\n",
        "\n",
        "# ------------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "df_24e = df_24.groupby(['id','status','type_ex']).apply(agg_func).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "s4nMFRWVl-Yf"
      },
      "outputs": [],
      "source": [
        "for i in ['pickup0_fail1', 'pickup0_fail2', 'pickup1_fail0', 'pickup1_fail1', 'pickup1_fail2']:\n",
        "  df_24e[i] = ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "XKQTaHm7UVK1"
      },
      "outputs": [],
      "source": [
        "# df_rbb['type'].fillna('rbb', inplace=True)\n",
        "# # df_o2o['type'].fillna('o2o', inplace=True)\n",
        "# df_o2o['type'].fillna('mj', inplace=True)\n",
        "# df_es['type'].fillna('estore', inplace=True)\n",
        "\n",
        "# df_ll['type'].fillna('langsunglaku', inplace=True)\n",
        "# df_ex['type'].fillna('exchange', inplace=True)\n",
        "\n",
        "# df_mj['type'].fillna('mj', inplace=True)\n",
        "\n",
        "# df_o2o.status.fillna('onprosess', inplace=True)\n",
        "\n",
        "# df_ex.loc[df_ex.seller_name == 'Xiaomi Official Store', 'type_ex'] = 'Xiaomi Official Store (Tokopedia)'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "o2_rqK5KS7xA"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Erland\\AppData\\Local\\Temp\\ipykernel_1880\\3474945815.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_log.n_req.fillna(1, inplace=True)\n",
            "C:\\Users\\Erland\\AppData\\Local\\Temp\\ipykernel_1880\\3474945815.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_log.n_rec.fillna(1, inplace=True)\n"
          ]
        }
      ],
      "source": [
        "# df_log = pd.concat([df_rbb, df_o2o, df_es, df_ll, df_ex, df_mj, df_24e], axis=0).drop_duplicates().reset_index().drop(columns=['index'])\n",
        "df_log = pd.concat([df_24e], axis=0).drop_duplicates().reset_index().drop(columns=['index'])\n",
        "df_log.n_req.fillna(1, inplace=True)\n",
        "df_log.n_rec.fillna(1, inplace=True)\n",
        "df_log.dropna(subset=['id','pickup0'], inplace=True)\n",
        "df_log = df_log[df_log.area != '-']\n",
        "df_log['logistic'] = df_log['logistic'].str.upper().replace(r'.*QIRIMAN.*', 'QIRIMAN', regex=True)\n",
        "\n",
        "mask = df_log['type_ex'].str.contains(r'estore', case=False, regex=True, na=False)\n",
        "df_log.loc[mask, 'type'] = 'estore'\n",
        "df_log.loc[mask, 'type_ex'] = ''\n",
        "df_log.loc[df_log.type_ex == '', 'type_ex'] = np.nan\n",
        "df_log.type_ex = df_log.type_ex.str.upper()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "IuiTKdzM9LAa"
      },
      "outputs": [],
      "source": [
        "df_log.loc[df_log['type'] == 'estore', 'type_ex'] = 'ESTORE'\n",
        "df_log['type'] = df_log['type'].replace('estore', 'exchange')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "Z0fstdxFccMT"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Erland\\AppData\\Local\\Temp\\ipykernel_1880\\375608365.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_log.status.fillna('In Progress', inplace=True)\n"
          ]
        }
      ],
      "source": [
        "status_mapping = {\n",
        "    'Recieved': 'Success',\n",
        "    'Partial Unit ': 'Success',\n",
        "    'No Unit ': 'Fail',\n",
        "    'Requested': 'In Progress',\n",
        "    'r2lk6-success': 'Success',\n",
        "    'Wrong IMEI ?': 'Success',\n",
        "    'pick up sukses': 'In Progress',\n",
        "    'Pick up success': 'Success',\n",
        "    'PIck up Fail': 'Fail',\n",
        "    'On process': 'In Progress',\n",
        "    'fraud': 'Fail',\n",
        "    'Cancel': 'Fail',\n",
        "    'cancel': 'Fail',\n",
        "    '-': 'In Progress',\n",
        "    'reschedule': 'In Progress',\n",
        "    'Onprosess': 'In Progress',\n",
        "    'onprosess': 'In Progress',\n",
        "    'exchange-success': 'Success',\n",
        "    'Exchange fail buyer': 'Fail',\n",
        "    'Exchange-success': 'Success',\n",
        "    'Exchange-fail seller': 'Fail',\n",
        "    'Exchange-fail': 'Fail',\n",
        "    'Pickup-success': 'In Progress',\n",
        "    'Pick up fail': 'Fail',\n",
        "    'Money in succsess': 'Success',\n",
        "    'Reschedule': 'In Progress',\n",
        "    'Pick up waiting': 'In Progress',\n",
        "    'Exchange-fail courier': 'Fail',\n",
        "    'Pickup fail': 'Fail',\n",
        "    'Exchange-otw': 'In Progress',\n",
        "    'Pending Pick up': 'In Progress',\n",
        "    'success': 'Success'\n",
        "}\n",
        "\n",
        "df_log['status'] = df_log['status'].replace(status_mapping)\n",
        "df_log.status.fillna('In Progress', inplace=True)\n",
        "\n",
        "df_log.loc[df_log['status'] != 'Success', 'received0'] = pd.NA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "hsNcng-vTcQw"
      },
      "outputs": [],
      "source": [
        "area_mapping = {\n",
        "    'KOTA JAKARTA UTARA': 'JAKARTA UTARA',\n",
        "    'KOTA BOGOR ': 'BOGOR',\n",
        "    ' JAKARTA UTARA': 'JAKARTA UTARA',\n",
        "    'KOTA TANGERANG SELATAN': 'TANGERANG SELATAN',\n",
        "    'KOTA MEDAN': 'MEDAN',\n",
        "    ' KOTA JAKARTA SELATAN': 'JAKARTA SELATAN',\n",
        "    'KOTA JAKARTA PUSAT': 'JAKARTA PUSAT',\n",
        "    'KOTA JAKARTA BARAT': 'JAKARTA BARAT',\n",
        "    'KOTA JAKARTA SELATAN': 'JAKARTA SELATAN',\n",
        "    'KOTA SURABAYA': 'SURABAYA',\n",
        "    'BOGOR TIMUR - KOTA': 'BOGOR',\n",
        "    'KOTA TANGERANG': 'TANGERANG',\n",
        "    'KOTA DEPOK': 'DEPOK',\n",
        "    'KOTA BOGOR': 'BOGOR',\n",
        "    'KOTA BEKASI': 'BEKASI',\n",
        "    'KOTA BANDUNG': 'BANDUNG',\n",
        "    'KOTA JAKARTA TIMUR ': 'JAKARTA TIMUR',\n",
        "    'KOTA JAKARTA TIMUR': 'JAKARTA TIMUR',\n",
        "    'KOTA JAKARTA SELATAN ': 'JAKARTA SELATAN',\n",
        "    'KAB. BOGOR': 'BOGOR',\n",
        "    ' SURABAYA': 'SURABAYA',\n",
        "    'DKI JAKARTA': 'JAKARTA',\n",
        "    'KAB. SIDOARDJO': 'SIDOARJO',\n",
        "    'KOTA MANADO': 'MANADO',\n",
        "    'KOTA PALEMBANG': 'PALEMBANG',\n",
        "    'KOTA PONITANAK': 'PONTIANAK',\n",
        "    'KOTA PONTIANAK': 'PONTIANAK',\n",
        "    'CIKARANG': 'BEKASI',\n",
        "    'KOTA JAKARTA PUSAT ': 'JAKARTA PUSAT',\n",
        "    'KOTA JAKARTA SELATAMN ': 'JAKARTA SELATAN',\n",
        "    'KOTA JAKARTA UTARA ': 'JAKARTA UTARA',\n",
        "    'KAB. TANGERANG': 'TANGERANG',\n",
        "    'KOTA SEMARANG': 'SEMARANG',\n",
        "    'KAB. SLEMAN': 'SLEMAN',\n",
        "    'KAB. BADUNG': 'BADUNG',\n",
        "    'KOTA BANDAR LAMPUNG': 'BANDAR LAMPUNG',\n",
        "    '-': 'Unknown',\n",
        "    'KOTA JAYAPURA': 'JAYAPURA',\n",
        "    'KOTA YOGYAKARTA': 'YOGYAKARTA',\n",
        "    'KAB. BOYOLALI': 'BOYOLALI',\n",
        "    'KAB. TULUNGAGUNG': 'TULUNGAGUNG',\n",
        "    'KAB. PANGKALAN KERINCI': 'PANGKALAN KERINCI',\n",
        "    'SURAKARTA': 'SOLO',\n",
        "    'JOGJA': 'YOGYAKARTA'\n",
        "}\n",
        "\n",
        "df_log['area'] = df_log['area'].str.upper().replace(area_mapping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "fLeY3TsUKLpw"
      },
      "outputs": [],
      "source": [
        "name_mapping = {'ACENG': 'KUSNADI PERMANA',\n",
        "                'ACENG JABO7': 'KUSNADI PERMANA',\n",
        "                'ANGGA': 'ANGGA WINANDA',\n",
        "                'AANG': 'AANG FERDIANSYAH',\n",
        "                'ANWAR': 'ANWAR EFENDI',\n",
        "                'BAYU': 'BAYU WIJAKSONO',\n",
        "                'FARHAN': 'FARHAN ARRIGHI DARMAWAN',\n",
        "                'DAVID': 'DAVID SANDRA',\n",
        "                'JALAL': 'JALALUDIN SUYUTI',\n",
        "                'KUSNADI': 'KUSNADI PERMANA',\n",
        "                'FAUZI': 'AHMAD FAUZI',\n",
        "                'YORDAN ALEXANDER': 'YORDAN ALEXANDER BATUALLO',\n",
        "                'DHAFFA RHESA BUDIAWAN': 'DAFFA RHESA BUDIAWAN',\n",
        "                'MUSTOFA J': 'JENAL MUSTOFA',\n",
        "                'RYAN JANUAR': 'RYAN JANUAR ARIANSYAH',\n",
        "                'HIDAYATULLAH AKSAN': 'AKSAN HIDAYATULLAH',\n",
        "                '0': np.nan,\n",
        "                'FATHUR CS': 'FATHUR',\n",
        "                'GILANG PRADANA': 'GILANG PRADANA SAPUTRA',\n",
        "                'HQ PROSES': np.nan,\n",
        "                'ISNAN ISTIGFARIAN': 'ISNAN ISTIGHFARIAN',\n",
        "                'MUHAMMAD IRPAN ARDIAN ': 'MUHAMMAD IRPAN ARDIAN',\n",
        "                'M IRPAN ARDIAN': 'MUHAMMAD IRPAN ARDIAN',\n",
        "                'RAMLAN KUNAEDI': 'RAMLAN KURNAEDI',\n",
        "                'REQUEST CS MAUJUAL': np.nan,\n",
        "                'TELESALES': np.nan,\n",
        "                'FAIZ AL HADI': 'A. FAIZ AL HADI',\n",
        "                'MUHAMAD YOGI FAHLEPI': 'YOGI FAHLEPI'\n",
        "\n",
        "                }\n",
        "\n",
        "df_log['courier_name'] = df_log['courier_name'].str.upper().replace(name_mapping)\n",
        "df_log['courier_name'] = df_log['courier_name'].str.upper().replace('.*QIRIMAN.*', np.nan, regex=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "26CIuP8R85hH"
      },
      "outputs": [],
      "source": [
        "mask = df_log.groupby(['pickup0','courier_name']).size().reset_index()['pickup0'] + ' ' + df_log.groupby(['pickup0','courier_name']).size().reset_index()['courier_name']\n",
        "mask = mask.tolist()\n",
        "\n",
        "def val0(x):\n",
        "  global mask\n",
        "  out = str(x['pickup0'])+' '+str(x['courier_name'])\n",
        "  if out in mask:\n",
        "    mask.remove(out)\n",
        "    return x['courier_name']\n",
        "\n",
        "df_log['val0'] = df_log.apply(val0, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "DY9Ti1ly4OPz"
      },
      "outputs": [],
      "source": [
        "mask_1 = df_log.groupby(['pickup0','courier_name','type']).size().reset_index()['pickup0'] + ' ' + df_log.groupby(['pickup0','courier_name','type']).size().reset_index()['courier_name'] + ' ' + df_log.groupby(['pickup0','courier_name','type']).size().reset_index()['type']\n",
        "mask_1 = mask_1.tolist()\n",
        "\n",
        "def val2(x):\n",
        "  global mask_1\n",
        "  out = str(x['pickup0'])+' '+str(x['courier_name'])+' '+str(x['type'])\n",
        "  if out in mask_1:\n",
        "    mask_1.remove(out)\n",
        "    return x['courier_name']\n",
        "\n",
        "df_log['val2'] = df_log.apply(val2, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "DsBKq6eXOcV9"
      },
      "outputs": [],
      "source": [
        "area_mapping = {\n",
        "    'SEMARANG': 'JAWA TENGAH',\n",
        "    'JAKARTA BARAT': 'JABODETABEK',\n",
        "    'BOGOR': 'JABODETABEK',\n",
        "    'BEKASI': 'JABODETABEK',\n",
        "    'SURABAYA': 'JAWA TIMUR',\n",
        "    'BANDUNG': 'JAWA BARAT',\n",
        "    'TANGERANG': 'JABODETABEK',\n",
        "    'JAKARTA PUSAT': 'JABODETABEK',\n",
        "    'JAKARTA UTARA': 'JABODETABEK',\n",
        "    'JAKARTA SELATAN': 'JABODETABEK',\n",
        "    'MEDAN': 'SUMATRA UTARA',\n",
        "    'SLEMAN': 'DI YOGYAKARTA',\n",
        "    'DEPOK': 'JABODETABEK',\n",
        "    'TANGERANG SELATAN': 'JABODETABEK',\n",
        "    'JAKARTA TIMUR': 'JABODETABEK',\n",
        "    'CIREBON': 'JAWA BARAT',\n",
        "    'MALANG': 'JAWA TIMUR',\n",
        "    'MOJOKERTO': 'JAWA TIMUR',\n",
        "    'PURWAKARTA': 'JAWA BARAT',\n",
        "    'SIDOARJO': 'JAWA TIMUR',\n",
        "    'TEGAL': 'JAWA TENGAH',\n",
        "    'KARAWANG': 'JAWA BARAT',\n",
        "    'INDRAGIRI HULU': 'RIAU',\n",
        "    'LHOKSEUMAWE': 'ACEH',\n",
        "    'BANDA ACEH': 'ACEH',\n",
        "    'KUNINGAN': 'JAWA BARAT',\n",
        "    'GORONTALO': 'GORONTALO',\n",
        "    'KUDUS': 'JAWA TENGAH',\n",
        "    'INDRAMAYU': 'JAWA BARAT',\n",
        "    'GIANYAR': 'BALI',\n",
        "    'KEDIRI': 'JAWA TIMUR',\n",
        "    'PALEMBANG': 'SUMATRA SELATAN',\n",
        "    'SUKOHARJO': 'JAWA TENGAH',\n",
        "    'DENPASAR': 'BALI',\n",
        "    'MAKASSAR': 'SULAWESI SELATAN',\n",
        "    'MANADO': 'SULAWESI UTARA',\n",
        "    'SUBANG': 'JAWA BARAT',\n",
        "    'PONTIANAK': 'KALIMANTAN BARAT',\n",
        "    'PEKANBARU': 'RIAU',\n",
        "    'BANDAR LAMPUNG': 'LAMPUNG',\n",
        "    'SOLO': 'JAWA TENGAH',\n",
        "    'GARUT': 'JAWA BARAT',\n",
        "    'PADANG': 'SUMATRA BARAT',\n",
        "    'BALIKPAPAN': 'KALIMANTAN TIMUR',\n",
        "    'CILEGON': 'BANTEN',\n",
        "    'JAMBI': 'JAMBI',\n",
        "    'MAGELANG': 'JAWA TENGAH',\n",
        "    'SERANG': 'BANTEN',\n",
        "    'TASIKMALAYA': 'JAWA BARAT',\n",
        "    'BANYUMAS': 'JAWA TENGAH',\n",
        "    'PALU': 'SULAWESI TENGAH',\n",
        "    'BANJARMASIN': 'KALIMANTAN SELATAN',\n",
        "    'PANGKAL PINANG': 'BANGKA BELITUNG',\n",
        "    'YOGYAKARTA': 'DI YOGYAKARTA',\n",
        "    'SUKABUMI': 'JAWA BARAT',\n",
        "    'MIMIKA': 'PAPUA',\n",
        "    'SUMBA TIMUR': 'NUSA TENGGARA TIMUR',\n",
        "    'BADUNG': 'BALI',\n",
        "    'JAYAPURA': 'PAPUA',\n",
        "    'ACEH TENGAH': 'ACEH',\n",
        "    'DELI SERDANG': 'SUMATRA UTARA',\n",
        "    'LEBAK': 'BANTEN',\n",
        "    'GRESIK': 'JAWA TIMUR',\n",
        "    'DUMAI': 'RIAU',\n",
        "    'JEMBER': 'JAWA TIMUR',\n",
        "    'SALATIGA': 'JAWA TENGAH',\n",
        "    'SORONG': 'PAPUA BARAT',\n",
        "    'ENDE': 'NUSA TENGGARA TIMUR',\n",
        "    'BANDUNG BARAT': 'JAWA BARAT',\n",
        "    'AMBON': 'MALUKU',\n",
        "    'SUMEDANG': 'JAWA BARAT',\n",
        "    'BATU': 'JAWA TIMUR',\n",
        "    'LUBUK LINGGAU': 'SUMATRA SELATAN',\n",
        "    'PALOPO': 'SULAWESI SELATAN',\n",
        "    'TABANAN': 'BALI',\n",
        "    'BANJARBARU': 'KALIMANTAN SELATAN',\n",
        "    'KOTABARU': 'KALIMANTAN SELATAN',\n",
        "    'LABUHANBATU': 'SUMATRA UTARA',\n",
        "    'BANYUWANGI': 'JAWA TIMUR',\n",
        "    'KOLAKA': 'SULAWESI TENGGARA',\n",
        "    'PEKALONGAN': 'JAWA TENGAH',\n",
        "    'KUPANG': 'NUSA TENGGARA TIMUR',\n",
        "    'JEMBRANA': 'BALI',\n",
        "    'BLITAR': 'JAWA TIMUR',\n",
        "    'BENGKULU': 'BENGKULU',\n",
        "    'BULELENG': 'BALI',\n",
        "    'OGAN KOMERING ULU': 'SUMATRA SELATAN',\n",
        "    'GUNUNGSITOLI': 'NUSA TENGGARA BARAT',\n",
        "    'BENGKALIS': 'RIAU',\n",
        "    'KENDARI': 'SULAWESI TENGGARA',\n",
        "    'TERNATE': 'MALUKU UTARA',\n",
        "    'MALUKU TENGGARA BARAT': 'MALUKU',\n",
        "    'ASAHAN': 'SUMATRA UTARA',\n",
        "    'PEMATANG SIANTAR': 'SUMATRA UTARA',\n",
        "    'CIMAHI': 'JAWA BARAT',\n",
        "    'KOTAMOBAGU': 'SULAWESI UTARA',\n",
        "    'BANGKA TENGAH': 'BANGKA BELITUNG',\n",
        "    'MADIUN': 'JAWA TIMUR',\n",
        "    'TULUNGAGUNG': 'JAWA TIMUR',\n",
        "    'SAMARINDA': 'KALIMANTAN TIMUR',\n",
        "    'SIKKA': 'NUSA TENGGARA TIMUR',\n",
        "    'NUSA TENGGARA TIMUR': 'NUSA TENGGARA TIMUR',\n",
        "    'METRO': 'LAMPUNG',\n",
        "    'GOWA': 'SULAWESI SELATAN',\n",
        "    'TANAH BUMBU': 'KALIMANTAN SELATAN',\n",
        "    'KLUNGKUNG': 'BALI',\n",
        "    'MATARAM': 'NUSA TENGGARA BARAT',\n",
        "    'TEBING TINGGI': 'SUMATRA UTARA',\n",
        "    'NABIRE': 'PAPUA',\n",
        "    'BUKITTINGGI': 'SUMATRA BARAT',\n",
        "    'SIMALUNGUN': 'SUMATRA UTARA',\n",
        "    'PULANG PISAU': 'KALIMANTAN TENGAH',\n",
        "    'KEBUMEN': 'JAWA TENGAH',\n",
        "    'TANAH LAUT': 'KALIMANTAN SELATAN',\n",
        "    'JAKARTA': 'JABODETABEK',\n",
        "    'BATAM': 'KEPULAUAN RIAU',\n",
        "    'RIAU': 'RIAU',\n",
        "    'TAPANULI': 'SUMATRA UTARA',\n",
        "    'BENAWA': 'SUMATRA SELATAN',\n",
        "    'BINJAI': 'SUMATRA UTARA',\n",
        "    'PAMEKASAN': 'JAWA TIMUR',\n",
        "    'JEPARA': 'JAWA TENGAH',\n",
        "    'SRAGEN': 'JAWA TENGAH',\n",
        "    'MINAHASA': 'SULAWESI UTARA',\n",
        "    'KOTAWARINGIN': 'KALIMANTAN TENGAH',\n",
        "    'PROBOLINGGO': 'JAWA TIMUR',\n",
        "    'CILACAP': 'JAWA TENGAH',\n",
        "    'BALI': 'BALI',\n",
        "    'HALMAHERA': 'MALUKU UTARA',\n",
        "    'BOYOLALI': 'JAWA TENGAH',\n",
        "    'TULUNG AGUNG': 'JAWA TIMUR',\n",
        "    'PANGKALAN KERINCI': 'RIAU',\n",
        "    'TANGERANG SELATAN': 'JABODETABEK',\n",
        "    'MANGGARAI': 'NUSA TENGGARA TIMUR',\n",
        "    'BANJAR': 'JAWA TENGAH & DI YOGYAKARTA',\n",
        "    'SAMOSIR': 'SUMATRA',\n",
        "    'BERAU': 'KALIMANTAN',\n",
        "    'MEDAN PETISAH': 'SUMATRA',\n",
        "    'PENJARINGAN': 'JABODETABEK',\n",
        "    'TANGERANG SELATAN': 'JABODETABEK'\n",
        "}\n",
        "\n",
        "df_log['val1'] = df_log.area.str.upper().map(area_mapping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "kvQxdzPFQmoF"
      },
      "outputs": [],
      "source": [
        "area_mapping = {\n",
        "    'SUMATRA UTARA': 'SUMATRA',\n",
        "    'DI YOGYAKARTA': 'JAWA TENGAH & DI YOGYAKARTA',\n",
        "    'RIAU': 'SUMATRA',\n",
        "    'ACEH': 'SUMATRA',\n",
        "    'GORONTALO': 'SULAWESI',\n",
        "    'BALI': 'BALI & NUSA TENGGARA',\n",
        "    'SUMATRA SELATAN': 'SUMATRA',\n",
        "    'SULAWESI SELATAN': 'SULAWESI',\n",
        "    'SULAWESI UTARA': 'SULAWESI',\n",
        "    'KALIMANTAN BARAT': 'KALIMANTAN',\n",
        "    'LAMPUNG': 'SUMATRA',\n",
        "    'SUMATRA BARAT': 'SUMATRA',\n",
        "    'KALIMANTAN TIMUR': 'KALIMANTAN',\n",
        "    'BANTEN': 'JAWA BARAT & BANTEN',\n",
        "    'JAMBI': 'SUMATRA',\n",
        "    'SULAWESI TENGAH': 'SULAWESI',\n",
        "    'KALIMANTAN SELATAN': 'KALIMANTAN',\n",
        "    'BANGKA BELITUNG': 'SUMATRA',\n",
        "    'PAPUA': 'PAPUA & MALUKU',\n",
        "    'NUSA TENGGARA TIMUR': 'BALI & NUSA TENGGARA',\n",
        "    'PAPUA BARAT': 'PAPUA & MALUKU',\n",
        "    'MALUKU': 'PAPUA & MALUKU',\n",
        "    'SULAWESI TENGGARA': 'SULAWESI',\n",
        "    'BENGKULU': 'SUMATRA',\n",
        "    'NUSA TENGGARA BARAT': 'BALI & NUSA TENGGARA',\n",
        "    'MALUKU UTARA': 'PAPUA & MALUKU',\n",
        "    'KALIMANTAN TENGAH': 'KALIMANTAN',\n",
        "    'KEPULAUAN RIAU': 'SUMATRA',\n",
        "    'JAWA TENGAH': 'JAWA TENGAH & DI YOGYAKARTA',\n",
        "    'JAWA BARAT': 'JAWA BARAT & BANTEN'\n",
        "}\n",
        "\n",
        "df_log['val1'] = df_log.val1.replace(area_mapping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "HDYOpzXfEq6J"
      },
      "outputs": [],
      "source": [
        "salary_mapping = {\n",
        "    'AGUSTINUS OSVALDO RIOS MALAU': 125000,\n",
        "    'AHMAD FAUZI': 128846,\n",
        "    'AKSAN HIDAYATULLAH': 100000,\n",
        "    'ALDI ARDIANA': 125000,\n",
        "    'ALFIN RAHMAD ZAKARIA': 125000,\n",
        "    'AMIRRUDIN': 128846,\n",
        "    'AZI SETIAWAN': 100000,\n",
        "    'BASUNDARA DEVITO': 100000,\n",
        "    'BAYU WIJAKSONO': 128846,\n",
        "    'DAFFA RHESA BUDIAWAN': 128846,\n",
        "    'DARKONI': 128846,\n",
        "    'DAVID SANDRA': 128846,\n",
        "    'FAIZ AL HADI': 125000,\n",
        "    'FATHUDDIN YUSUF': 128846,\n",
        "    'FIRDAUS': 128846,\n",
        "    'FURKON RAMADANI': 100000,\n",
        "    'GILANG PRADANA SAPUTRA': 128846,\n",
        "    'HADI MURDIANSYAH': 128846,\n",
        "    'HIJANI TRIADI ACHMAD': 125000,\n",
        "    'IRFAN MAULANA YUSUP': 100000,\n",
        "    'ISNAN ISTIGHFARIAN': 128846,\n",
        "    'JENAL MUSTOFA': 128846,\n",
        "    'KRISHARYANTO': 100000,\n",
        "    'MARULITUA MANALU': 100000,\n",
        "    'MOHAMMAD IQBAL': 128846,\n",
        "    'MUHAMAD RIDWAN': 100000,\n",
        "    'MUHAMMAD IRPAN ARDIAN': 100000,\n",
        "    'PUAD MAHPUDIN': 100000,\n",
        "    'PURNAMA SUDARYANTO': 0,\n",
        "    'RAMLAN KURNAEDI': 100000,\n",
        "    'RANDI PRIANDI': 128846,\n",
        "    'RYAN JANUAR ARIANSYAH': 100000,\n",
        "    'YOGI FAHLEPI': 100000,\n",
        "    'YORDAN ALEXANDER BATUALLO': 128846,\n",
        "    'A. FAIZ AL HADI': 125000,\n",
        "    'AANG FERDIANSYAH': 125000,\n",
        "    'ANGGA WINANDA': 125000,\n",
        "    'ANWAR EFENDI': 125000,\n",
        "    'BIMA': 125000,\n",
        "    'DIMAS': 125000,\n",
        "    'ELZA': 125000,\n",
        "    'FARHAN ARRIGHI DARMAWAN': 125000,\n",
        "    'FATHUR': 125000,\n",
        "    'FIKRI': 125000,\n",
        "    'FIRMAN': 125000,\n",
        "    'HANIFAL QALBY': 100000,\n",
        "    'HENDI KRISDIANSYAH': 125000,\n",
        "    'JALALUDIN SUYUTI': 125000,\n",
        "    'KUSNADI PERMANA': 125000,\n",
        "    'MUHAMAD SALIM': 125000,\n",
        "    'MUHAMMAD HADYAN': 100000,\n",
        "    'PEBRO RANGGA ARDI': 125000,\n",
        "    'PURNAMA SUDARYANTO': 100000\n",
        "}\n",
        "\n",
        "allowance_mapping = {\n",
        "    'AGUSTINUS OSVALDO RIOS MALAU': 34500,\n",
        "    'AHMAD FAUZI': 50500,\n",
        "    'AKSAN HIDAYATULLAH': 20000,\n",
        "    'ALDI ARDIANA': 34500,\n",
        "    'ALFIN RAHMAD ZAKARIA': 34500,\n",
        "    'AMIRRUDIN': 50500,\n",
        "    'AZI SETIAWAN': 20000,\n",
        "    'BASUNDARA DEVITO': 20000,\n",
        "    'BAYU WIJAKSONO': 50500,\n",
        "    'DAFFA RHESA BUDIAWAN': 50500,\n",
        "    'DARKONI': 50500,\n",
        "    'DAVID SANDRA': 50500,\n",
        "    'FAIZ AL HADI': 34500,\n",
        "    'FATHUDDIN YUSUF': 50500,\n",
        "    'FIRDAUS': 50500,\n",
        "    'FURKON RAMADANI': 20000,\n",
        "    'GILANG PRADANA SAPUTRA': 50500,\n",
        "    'HADI MURDIANSYAH': 50500,\n",
        "    'HIJANI TRIADI ACHMAD': 34500,\n",
        "    'IRFAN MAULANA YUSUP': 20000,\n",
        "    'ISNAN ISTIGHFARIAN': 50500,\n",
        "    'JENAL MUSTOFA': 50500,\n",
        "    'KRISHARYANTO': 20000,\n",
        "    'MARULITUA MANALU': 20000,\n",
        "    'MOHAMMAD IQBAL': 50500,\n",
        "    'MUHAMAD RIDWAN': 20000,\n",
        "    'MUHAMMAD IRPAN ARDIAN': 20000,\n",
        "    'PUAD MAHPUDIN': 20000,\n",
        "    'PURNAMA SUDARYANTO': 50500,\n",
        "    'RAMLAN KURNAEDI': 20000,\n",
        "    'RANDI PRIANDI': 50500,\n",
        "    'RYAN JANUAR ARIANSYAH': 20000,\n",
        "    'YOGI FAHLEPI': 20000,\n",
        "    'A. FAIZ AL HADI': 34500,\n",
        "    'AANG FERDIANSYAH': 34500,\n",
        "    'ANGGA WINANDA': 34500,\n",
        "    'ANWAR EFENDI': 34500,\n",
        "    'BIMA': 34500,\n",
        "    'DIMAS': 34500,\n",
        "    'ELZA': 34500,\n",
        "    'FARHAN ARRIGHI DARMAWAN': 34500,\n",
        "    'FATHUR': 34500,\n",
        "    'FIKRI': 34500,\n",
        "    'FIRMAN': 34500,\n",
        "    'HANIFAL QALBY': 20000,\n",
        "    'HENDI KRISDIANSYAH': 34500,\n",
        "    'JALALUDIN SUYUTI': 34500,\n",
        "    'KUSNADI PERMANA': 34500,\n",
        "    'MUHAMAD SALIM': 34500,\n",
        "    'MUHAMMAD HADYAN': 20000,\n",
        "    'PEBRO RANGGA ARDI': 34500,\n",
        "    'PURNAMA SUDARYANTO': 20000,\n",
        "    'YORDAN ALEXANDER BATUALLO': 50500\n",
        "}\n",
        "\n",
        "monthly_mapping = {\n",
        "    'AGUSTINUS OSVALDO RIOS MALAU': 'Daily Worker',\n",
        "    'AHMAD FAUZI': 'Contract',\n",
        "    'AKSAN HIDAYATULLAH': 'Daily Worker',\n",
        "    'ALDI ARDIANA': 'Daily Worker',\n",
        "    'ALFIN RAHMAD ZAKARIA': 'Daily Worker',\n",
        "    'AMIRRUDIN': 'Contract',\n",
        "    'AZI SETIAWAN': 'Daily Worker',\n",
        "    'BASUNDARA DEVITO': 'Daily Worker',\n",
        "    'BAYU WIJAKSONO': 'Contract',\n",
        "    'DAFFA RHESA BUDIAWAN': 'Contract',\n",
        "    'DARKONI': 'Contract',\n",
        "    'DAVID SANDRA': 'Contract',\n",
        "    'FAIZ AL HADI': 'Daily Worker',\n",
        "    'FATHUDDIN YUSUF': 'Contract',\n",
        "    'FIRDAUS': 'Contract',\n",
        "    'FURKON RAMADANI': 'Daily Worker',\n",
        "    'GILANG PRADANA SAPUTRA': 'Contract',\n",
        "    'HADI MURDIANSYAH': 'Contract',\n",
        "    'HIJANI TRIADI ACHMAD': 'Daily Worker',\n",
        "    'IRFAN MAULANA YUSUP': 'Daily Worker',\n",
        "    'ISNAN ISTIGHFARIAN': 'Contract',\n",
        "    'JENAL MUSTOFA': 'Contract',\n",
        "    'KRISHARYANTO': 'Daily Worker',\n",
        "    'MARULITUA MANALU': 'Daily Worker',\n",
        "    'MOHAMMAD IQBAL': 'Contract',\n",
        "    'MUHAMAD RIDWAN': 'Daily Worker',\n",
        "    'MUHAMMAD IRPAN ARDIAN': 'Daily Worker',\n",
        "    'PUAD MAHPUDIN': 'Daily Worker',\n",
        "    'PURNAMA SUDARYANTO': 'Daily Worker',\n",
        "    'RAMLAN KURNAEDI': 'Daily Worker',\n",
        "    'RANDI PRIANDI': 'Contract',\n",
        "    'RYAN JANUAR ARIANSYAH': 'Daily Worker',\n",
        "    'YOGI FAHLEPI': 'Daily Worker',\n",
        "    'YORDAN ALEXANDER BATUALLO': 'Contract',\n",
        "    'A. FAIZ AL HADI': 'Daily Worker',\n",
        "    'AANG FERDIANSYAH': 'Daily Worker',\n",
        "    'ANGGA WINANDA': 'Daily Worker',\n",
        "    'ANWAR EFENDI': 'Daily Worker',\n",
        "    'BIMA': 'Daily Worker',\n",
        "    'DIMAS': 'Daily Worker',\n",
        "    'ELZA': 'Daily Worker',\n",
        "    'FARHAN ARRIGHI DARMAWAN': 'Daily Worker',\n",
        "    'FATHUR': 'Daily Worker',\n",
        "    'FIKRI': 'Daily Worker',\n",
        "    'FIRMAN': 'Daily Worker',\n",
        "    'HANIFAL QALBY': 'Daily Worker',\n",
        "    'HENDI KRISDIANSYAH': 'Daily Worker',\n",
        "    'JALALUDIN SUYUTI': 'Daily Worker',\n",
        "    'KUSNADI PERMANA': 'Daily Worker',\n",
        "    'MUHAMAD SALIM': 'Daily Worker',\n",
        "    'MUHAMMAD HADYAN': 'Daily Worker',\n",
        "    'PEBRO RANGGA ARDI': 'Daily Worker',\n",
        "    'PURNAMA SUDARYANTO': 'Daily Worker'\n",
        "}\n",
        "\n",
        "df_log['courier_salary'] = df_log['val2'].map(salary_mapping).fillna('')\n",
        "df_log['courier_allowance'] = df_log['val2'].map(allowance_mapping).fillna('')\n",
        "df_log['courier_monthly'] = df_log['courier_name'].map(monthly_mapping).fillna('')\n",
        "# df_log['courier_salary_val0'] = df_log['val0'].map(salary_mapping).fillna('')\n",
        "# df_log['courier_allowance_val0'] = df_log['val0'].map(allowance_mapping).fillna('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "BUWEWMqJfMxs"
      },
      "outputs": [],
      "source": [
        "# set date range\n",
        "\n",
        "df_log = df_log[(pd.to_datetime(df_log.pickup0) >= pd.Timestamp('2024-01-01')) &\n",
        "                (pd.to_datetime(df_log['pickup0']) <= pd.Timestamp.now().normalize())]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQkbYmQoXrMo",
        "outputId": "e754bab3-62e4-46d3-b997-ef745e4d99af"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "\n",
        "ct = datetime.datetime.now()+ datetime.timedelta()\n",
        "# df_log.loc[0, 'last_update'] = str(ct.strftime('%b, %d %Y %H:%M:%S'))\n",
        "df_log['last_update'] = str(ct.strftime('%b, %d %Y %H:%M:%S'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "wA4pep-eTQnm"
      },
      "outputs": [],
      "source": [
        "#swap\n",
        "# mask = (df_log['pickup0'] > df_log['received0'])\n",
        "\n",
        "# df_log.loc[mask, ['pickup0', 'received0']] = df_log.loc[mask, ['received0', 'pickup0']].values\n",
        "# df_log['pickup0'], df_log['received0'] = np.where(mask, [df_log['received0'], df_log['pickup0']], [df_log['pickup0'], df_log['received0']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrcsA9pSyGEq",
        "outputId": "c0b4b043-f96f-41a6-8ed7-0842d2cc0b30"
      },
      "outputs": [],
      "source": [
        "df_log['pickup1'] = ''\n",
        "df_log['received1'] = ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJt24rVHWu5K",
        "outputId": "814b7403-d488-41fe-fb82-9e2266011113"
      },
      "outputs": [],
      "source": [
        "df_log['pickup0'] = pd.to_datetime(df_log['pickup0'])\n",
        "df_log['pickup1'] = pd.to_datetime(df_log['pickup1'])\n",
        "df_log['received0'] = pd.to_datetime(df_log['received0'])\n",
        "df_log['received1'] = pd.to_datetime(df_log['received1'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "RnbKE1LTLHiH"
      },
      "outputs": [],
      "source": [
        "df_log['pickup0'], df_log['received0'] = np.where(df_log['pickup0'] > df_log['received0'], [df_log['received0'], df_log['pickup0']], [df_log['pickup0'], df_log['received0']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "cFBWlAyZGGie"
      },
      "outputs": [],
      "source": [
        "df_log.pickup0_fail0 = df_log.pickup0_fail0.replace('0','')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "Xa5-vE3YdsEH"
      },
      "outputs": [],
      "source": [
        "df_log['week'] = df_log['pickup0'].dt.isocalendar().week"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "zruFwAxncviP"
      },
      "outputs": [],
      "source": [
        "df_log.loc[df_log['status'] == 'In Progress', 'received0'] = ct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "DTPocwIYCms7"
      },
      "outputs": [],
      "source": [
        "df_log['received1'] = df_log['received0']\n",
        "df_log['pickup1'] = df_log['pickup0']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HH4NHz1FfgRt"
      },
      "source": [
        "## Export to spreadsheet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "MMiGNrKd6Ud0"
      },
      "outputs": [],
      "source": [
        "df_3pl_cost = pd.read_csv('https://docs.google.com/spreadsheets/d/16Nk5NHKQYj4DGhivT9obUqjNdPd3VcxFXD0GFRTNrcY/export?format=csv&gid=1816466187')\n",
        "df_3pl_cost = df_3pl_cost[df_3pl_cost['type'] == 'inbound']\n",
        "df_3pl_cost = df_3pl_cost[df_3pl_cost['cost'].notna()]\n",
        "df_3pl_cost['cost'] = df_3pl_cost['cost'].str.replace(',','').astype(int)\n",
        "\n",
        "log_area_list = df_log[df_log['area'].notna()]['area'].tolist()\n",
        "log_area_list.append('Surakartaa')\n",
        "\n",
        "def define_area(x):\n",
        "  for i in log_area_list:\n",
        "    if x.upper() == 'LAMPUNG':\n",
        "      return 'LAMPUNG'\n",
        "    elif (x.lower()+'_' in i.lower()+'_'):\n",
        "      return i\n",
        "    elif (i.lower()+'_' in x.lower()+'_'):\n",
        "      return i\n",
        "\n",
        "  return None\n",
        "\n",
        "df_3pl_cost['log_area'] = df_3pl_cost['area'].apply(define_area)\n",
        "\n",
        "df_log['area_lower'] = df_log['area'].str.strip().str.lower()\n",
        "df_log['logistic_lower'] = df_log['logistic'].str.strip().str.lower()\n",
        "df_3pl_cost['area_lower'] = df_3pl_cost['log_area'].str.strip().str.lower()\n",
        "df_3pl_cost['logistic_lower'] = df_3pl_cost['logistic'].str.strip().str.lower()\n",
        "\n",
        "cost_mapping = df_3pl_cost.set_index(['area_lower', 'logistic_lower'])['cost'].to_dict()\n",
        "\n",
        "cost_mapping = {k: v for k, v in cost_mapping.items() if not pd.isna(k[0])}\n",
        "\n",
        "def get_3pl_cost(row):\n",
        "    return cost_mapping.get((row['area_lower'], row['logistic_lower']), np.nan)\n",
        "\n",
        "df_log['3pl_cost'] = df_log.apply(get_3pl_cost, axis=1)\n",
        "\n",
        "\n",
        "# df_log.loc[df_log['logistic'].str.contains('indopaket', case=False, na=False), '3pl_cost'] = 44500\n",
        "\n",
        "df_log.drop(columns=['area_lower', 'logistic_lower'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "VoMj_9o6i-Yy"
      },
      "outputs": [],
      "source": [
        "# from google.colab import auth\n",
        "# auth.authenticate_user()\n",
        "\n",
        "# import gspread\n",
        "# from google.auth import default\n",
        "# creds, _ = default()\n",
        "\n",
        "# gc = gspread.authorize(creds)\n",
        "\n",
        "# from gspread_dataframe import set_with_dataframe\n",
        "\n",
        "# sh = gc.open('allogistic')\n",
        "# set_with_dataframe(sh.get_worksheet(0), df_log)\n",
        "\n",
        "# df_log.set_index('id').to_csv('/content/drive/MyDrive/allogistic.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "pulqWEMHWG4j"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install authlib\n",
        "!pip install google-api-python-client oauth2client\n",
        "!pip install gspread\n",
        "!pip install gspread_dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "-7f5pI-0E4MI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ['SHEET_TYPE'] = 'service_account'\n",
        "os.environ['SHEET_PROJECT_ID'] = 'macro-polymer-399408'\n",
        "os.environ['SHEET_PRIVATE_KEY_ID'] = 'e28490a79be94bc7ac7e1062583e21178cc90eaf'\n",
        "os.environ['SHEET_PRIVATE_KEY'] = '''-----BEGIN PRIVATE KEY-----\n",
        "MIIEvgIBADANBgkqhkiG9w0BAQEFAASCBKgwggSkAgEAAoIBAQC+zbq5R+4YTmgL\n",
        "Wm6/gwYHFp/L3mvppBRjTOKdrGK+SrDf2rL+85DbOVLRyGAZ5GaKgTUaGf/KiBt+\n",
        "n7MFFN1GcNPj0hNc3UYKcyi3l66JUdHpdLi8Hp53M7qa+K2Uc2rh+O96Fkc91ZN+\n",
        "RKkvNfTiBysdTXCITPJrhoZ0P7b5fwqXKuAPxtqtq1jJPE8utkf25fPjvjPGf9NY\n",
        "zBY/zGq2edvTknLd8RiWP8y929yAwRr1XJIgmRi4g/xS9hfQdgdom30JsQ96lB0x\n",
        "eU4ebe6K6uspOgAaN4nGkmRvLjWXUp5tuea0dBwtgfKTC1p1Y+ry9EpWxMY9dz6A\n",
        "509kVSIHAgMBAAECggEATt6XepMDFkUCuP6unLc6PJ/bedf8310VmF5lpitlvab+\n",
        "Keoq5zwi+ptdYp3jK5C/2izCmIF6vGs6gkLdKxKOzNlCnP9vRYmptBQaFpm6acTK\n",
        "cifvXMODWV6mmfyFM8HpwnK1+s9Or36jMySKkptJGE1CQyCJja3Q3yWCWncj2Uk1\n",
        "hvsx5WcbjDyDiTV5o1d9KuuXWz3escTbvt9gfsL2Rek7PvCd6UjIHsSLB9WT1RQB\n",
        "l7Jr2eIHOTsN0AuOVK0RNT39mkqXT/bbfX1yNxmU/5xn7r/Civpw1r7Xnl223HLU\n",
        "7kSsKZKwv+yoT8jbH+3VyIU8LUGeHDS5uyl/IJDdQQKBgQDhC8cdG4go4P0A03OJ\n",
        "hcjJty/BOlMlwAHyI7xvBNvbzKk2+XB+/SQ1BML1QigdvrSrjUtBrnI9TeO0Rv9S\n",
        "oe1/xbyNzHdZkz8Hk0ClUteJJKGu+rK1zTWdOSPn1ymmbC7bsGoUKwMmpr5YPEx1\n",
        "uoIBerlwVPkyeeiCkgOCZo6c9wKBgQDZDDlSpRUWM8x0ESRQxlgkDewKkS1FezQF\n",
        "84sTczqZOXbSBXi23rb9UHcsdDFu3JXtEz6VfA53N0Wz9IPa25sg5KGiS3SMxaap\n",
        "bm7xXa+lQFJZY+LPgDK+jsHyC7EfizYK9vq2OPAwyngm6aAKRt2Mf1Ofc0XFfco2\n",
        "gB/cslOvcQKBgCbwrsdumCTaqWyXKgrFx3R/6hd5TCHgE3YekOB06sYhp7YHe1u9\n",
        "2aIC7OkbRW3ALerxS/BVixbof1oWXt+hfUL6qCGxG4W4YNOiuzDgIMNuPzvTzVB/\n",
        "7aMC3B+lr2NInOMOp4xN1QG/IHiMFn7Ygt5Wqfex/Fyrk3vkYA8UR+EJAoGBAISh\n",
        "46WNG4WlwZprnzV8/v+JQmRysqdy0ieQ27vW/kgDxYgxr8KP9mJ1eV3A4zRLt5JX\n",
        "4DaYyH4xWHbPRIPJDtLa46q5UU90uJNw2HrGNT9WPvxA/aivPlMUCZBPdL1B5JRu\n",
        "uGYCBUTLdQDSYunkxB3G8OLPHiPA6oDDarUChAEBAoGBAIBBEqcRk5LWUkl19cat\n",
        "D8+AZfR5Zs6sQzOCh7I6JcY9mGHlNa6Cu+hAVJRo5mIZkQClNcZE7Jk9lCuf2lGd\n",
        "ngWHVlgAzRz0PsrtDZsb8o6k4Oa3GG65DdOwsixjji5/i10UNMgoFn22bvwmnlvk\n",
        "N5goLfz696qMuYmqOVB1Mpka\n",
        "-----END PRIVATE KEY-----'''\n",
        "os.environ['SHEET_CLIENT_EMAIL'] = 'ops-864@macro-polymer-399408.iam.gserviceaccount.com'\n",
        "os.environ['SHEET_CLIENT_ID'] = '113749509940777766546'\n",
        "os.environ['SHEET_AUTH_URI'] = 'https://accounts.google.com/o/oauth2/auth'\n",
        "os.environ['SHEET_TOKEN_URI'] = 'https://oauth2.googleapis.com/token'\n",
        "os.environ['SHEET_AUTH_PROVIDER_X509_CERT_URL'] = 'https://www.googleapis.com/oauth2/v1/certs'\n",
        "os.environ['SHEET_CLIENT_X509_CERT_URL'] = 'https://www.googleapis.com/robot/v1/metadata/x509/ops-864%40macro-polymer-399408.iam.gserviceaccount.com'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "APvVO7eSEsFN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def create_keyfile_dict():\n",
        "    variables_keys = {\n",
        "        \"type\": os.environ.get(\"SHEET_TYPE\"),\n",
        "        \"project_id\": os.environ.get(\"SHEET_PROJECT_ID\"),\n",
        "        \"private_key_id\": os.environ.get(\"SHEET_PRIVATE_KEY_ID\"),\n",
        "        \"private_key\": os.environ.get(\"SHEET_PRIVATE_KEY\").replace(\"\\\\n\", \"\\n\"),\n",
        "        \"client_email\": os.environ.get(\"SHEET_CLIENT_EMAIL\"),\n",
        "        \"client_id\": os.environ.get(\"SHEET_CLIENT_ID\"),\n",
        "        \"auth_uri\": os.environ.get(\"SHEET_AUTH_URI\"),\n",
        "        \"token_uri\": os.environ.get(\"SHEET_TOKEN_URI\"),\n",
        "        \"auth_provider_x509_cert_url\": os.environ.get(\"SHEET_AUTH_PROVIDER_X509_CERT_URL\"),\n",
        "        \"client_x509_cert_url\": os.environ.get(\"SHEET_CLIENT_X509_CERT_URL\"),\n",
        "    }\n",
        "    return variables_keys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "yG7daUbH06Ez"
      },
      "outputs": [],
      "source": [
        "import gspread\n",
        "from gspread_dataframe import set_with_dataframe\n",
        "from gspread import Client\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "\n",
        "scope = ['https://spreadsheets.google.com/feeds','https://www.googleapis.com/auth/drive']\n",
        "\n",
        "creds = ServiceAccountCredentials.from_json_keyfile_dict(create_keyfile_dict(), scope)\n",
        "\n",
        "client = gspread.authorize(creds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "CghW-FCgGc5x"
      },
      "outputs": [],
      "source": [
        "# df_log.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# df_log['index'] = df_log.index\n",
        "# columns = list(df_log.columns)\n",
        "# columns.append(columns.pop(columns.index('index')))\n",
        "# df_log = df_log[columns]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "ibn8v9x02wLA"
      },
      "outputs": [],
      "source": [
        "sheet = client.open(\"allogistic\")\n",
        "sheet.worksheet('data').clear()\n",
        "set_with_dataframe(sheet.get_worksheet(0), df_log)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0l0HFipmBXQ"
      },
      "source": [
        "#### additional"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "olO041gH2YWx"
      },
      "outputs": [],
      "source": [
        "df_is = pd.read_csv('https://docs.google.com/spreadsheets/d/16Nk5NHKQYj4DGhivT9obUqjNdPd3VcxFXD0GFRTNrcY/export?format=csv&gid=1601826919')\n",
        "df_is['imei_list'] = df_is['imei_list'].astype(str)\n",
        "\n",
        "df_is['postal_code'] = df_is['postal_code'].apply(lambda x: f\"{int(x)}\" if pd.notnull(x) else '')\n",
        "\n",
        "df_1 = df_is[df_is['delivery_service_name'].str.contains('lakusend|-|QIRIMAN', case=False, na=False) &\n",
        "        (df_is['delivery_service_name'] != 'REX - TV')]\n",
        "df_2 = df_is[~df_is['delivery_service_name'].str.contains('lakusend|-|QIRIMAN', case=False, na=False) |\n",
        "             df_is['delivery_service_name'].str.contains('REX - TV', case=False, na=False)]\n",
        "\n",
        "df_a = df_log.copy()\n",
        "\n",
        "df_a.drop_duplicates(subset=['id', 'rbb_schedule'], keep='last', inplace=True)\n",
        "df_a = df_a[['id', 'rbb_schedule', 'logistic']]\n",
        "\n",
        "df_merge = df_1.merge(df_a[['id', 'logistic']], left_on='tracking_number', right_on='id', how='left', suffixes=('', '_track'))\n",
        "\n",
        "\n",
        "\n",
        "imei_to_logistic = dict(zip(df_a['rbb_schedule'], df_a['logistic']))\n",
        "\n",
        "def get_logistic(imei_list, imei_to_logistic):\n",
        "    for imei in imei_list.split(','):\n",
        "        imei = imei.strip()\n",
        "        if imei in imei_to_logistic:\n",
        "            return imei_to_logistic[imei]\n",
        "    return None\n",
        "\n",
        "df_merge['logistic_x'] = df_merge['imei_list'].apply(get_logistic, args=(imei_to_logistic,))\n",
        "df_merge['logistic'] = df_merge['logistic'].fillna(df_merge['logistic_x'])\n",
        "\n",
        "df_merge.rename(columns={'logistic': 'fflog_logistic'}, inplace=True)\n",
        "\n",
        "\n",
        "# df_merge['delivery_service_name'] = df_merge['fflog_logistic'].fillna(df_merge['delivery_service_name'])\n",
        "\n",
        "def check_condition(row):\n",
        "    delivery_service_name = row['delivery_service_name']\n",
        "    fflog_logistic = row['fflog_logistic']\n",
        "\n",
        "    # Handle None/NaN values\n",
        "    if pd.isna(delivery_service_name):\n",
        "        delivery_service_name = ''\n",
        "    if pd.isna(fflog_logistic):\n",
        "        fflog_logistic = ''\n",
        "\n",
        "    # Check if both contain 'qiriman'\n",
        "    if 'qiriman' in delivery_service_name.lower() and 'qiriman' in fflog_logistic.lower():\n",
        "        return False  # Do not update\n",
        "    return True  # Update\n",
        "\n",
        "condition = df_merge.apply(check_condition, axis=1)\n",
        "df_merge['delivery_service_name'] = np.where(condition, df_merge['fflog_logistic'].fillna(df_merge['delivery_service_name']), df_merge['delivery_service_name'])\n",
        "\n",
        "df_merge.drop(columns=['logistic_x', 'fflog_logistic'], inplace=True)\n",
        "\n",
        "# df_merge[df_merge['delivery_service_name'].str.contains('QIRIMAN')]\n",
        "\n",
        "final_result = pd.concat([df_merge, df_2])\n",
        "\n",
        "final_result['area_lower'] = final_result['area'].str.strip().str.lower()\n",
        "final_result['logistic_lower'] = final_result['delivery_service_name'].str.strip().str.lower()\n",
        "\n",
        "final_result['3pl_cost'] = final_result.apply(get_3pl_cost, axis=1)\n",
        "\n",
        "final_result.loc[final_result['delivery_service_name'].str.contains('indopaket', case=False, na=False), '3pl_cost'] = 44500\n",
        "\n",
        "final_result = final_result.reset_index(drop=True)\n",
        "\n",
        "final_result.loc[final_result['delivery_service_name'] == 'QIRIMAN', 'delivery_service_name'] = final_result['delivery_service_name'] + ' ' + final_result['area']\n",
        "\n",
        "final_result.drop(columns=['area_lower', 'logistic_lower'], inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "df_indopaket_cost = pd.read_csv('https://docs.google.com/spreadsheets/d/16Nk5NHKQYj4DGhivT9obUqjNdPd3VcxFXD0GFRTNrcY/export?format=csv&gid=1497570630')\n",
        "df_indopaket_cost['postal_code'] = df_indopaket_cost['postal_code'].astype(str)\n",
        "\n",
        "final_result = final_result.merge(df_indopaket_cost, on='postal_code', how='left')\n",
        "\n",
        "\n",
        "final_result.loc[final_result['delivery_service_name'].str.contains('indopaket', case=False, na=False), '3pl_cost'] = final_result['indopaket_cost']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "P-gbxsKDnMk5"
      },
      "outputs": [],
      "source": [
        "# final_result[final_result['imei_list'] == '864763068869062']\n",
        "# df_merge[df_merge['tracking_number'] == 'INTKP20240524820916_B']\n",
        "\n",
        "# for i, j in cost_mapping_cleaned:\n",
        "#   if cost_mapping_cleaned[i,j] == 270500:\n",
        "#     print(i, j)\n",
        "\n",
        "# # len(cost_mapping)\n",
        "# # cost_mapping_cleaned = {k: v for k, v in cost_mapping.items() if not pd.isna(k[0])}\n",
        "# # cost_mapping_cleaned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "RqkrIk38Fm-D"
      },
      "outputs": [],
      "source": [
        "sheet.worksheet('data_2').clear()\n",
        "set_with_dataframe(sheet.worksheet('data_2'), final_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "Inecwj7jTZMa"
      },
      "outputs": [],
      "source": [
        "# sheet.worksheet('data_2').clear()\n",
        "\n",
        "# df_log.drop_duplicates(subset=['id', 'rbb_schedule'], keep='last', inplace=True)\n",
        "# df_log = df_log[['id', 'rbb_schedule', 'logistic', 'type']]\n",
        "\n",
        "# set_with_dataframe(sheet.worksheet('data_2'), df_log)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hi2Jigj9TWAx"
      },
      "source": [
        "#test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "sVbQXgeITfTw"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "alert(\"Script execution completed!\");",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import Javascript\n",
        "display(Javascript('alert(\"Script execution completed!\");'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "EcKPLt8xdrYt"
      },
      "outputs": [],
      "source": [
        "# df_3pl_cost = pd.read_csv('https://docs.google.com/spreadsheets/d/16Nk5NHKQYj4DGhivT9obUqjNdPd3VcxFXD0GFRTNrcY/export?format=csv&gid=1816466187')\n",
        "# df_3pl_cost = df_3pl_cost[df_3pl_cost['cost'].notna()]\n",
        "# df_3pl_cost['cost'] = df_3pl_cost['cost'].str.replace(',','').astype(int)\n",
        "\n",
        "# log_area_list = df_log[df_log['area'].notna()]['area'].tolist()\n",
        "\n",
        "# def define_area(x):\n",
        "#   for i in log_area_list:\n",
        "#     if x.upper() == 'LAMPUNG':\n",
        "#       return 'LAMPUNG'\n",
        "#     elif (x.lower()+'_' in i.lower()+'_'):\n",
        "#       return i\n",
        "#     elif (i.lower()+'_' in x.lower()+'_'):\n",
        "#       return i\n",
        "\n",
        "#   return None\n",
        "\n",
        "# df_3pl_cost['log_area'] = df_3pl_cost['area'].apply(define_area)\n",
        "\n",
        "# df_log['area_lower'] = df_log['area'].str.strip().str.lower()\n",
        "# df_log['logistic_lower'] = df_log['logistic'].str.strip().str.lower()\n",
        "# df_3pl_cost['area_lower'] = df_3pl_cost['log_area'].str.strip().str.lower()\n",
        "# df_3pl_cost['logistic_lower'] = df_3pl_cost['logistic'].str.strip().str.lower()\n",
        "\n",
        "# cost_mapping = df_3pl_cost.set_index(['area_lower', 'logistic_lower'])['cost'].to_dict()\n",
        "\n",
        "# def get_3pl_cost(row):\n",
        "#     return cost_mapping.get((row['area_lower'], row['logistic_lower']), np.nan)\n",
        "\n",
        "# df_log['3pl_cost'] = df_log.apply(get_3pl_cost, axis=1)\n",
        "\n",
        "# df_log.loc[df_log['logistic'].str.contains('indopaket', case=False, na=False), '3pl_cost'] = 44500\n",
        "\n",
        "# df_log.drop(columns=['area_lower', 'logistic_lower'], inplace=True)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "pau9t5HruIvl"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
